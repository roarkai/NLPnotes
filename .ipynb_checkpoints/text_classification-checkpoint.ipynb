{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed2d5716",
   "metadata": {},
   "source": [
    "# Text classification\n",
    "<font color=brown>[ref: chapter4 of SLP, lecture 1 of cmu 11-711 spring 2024]</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd769f1e",
   "metadata": {},
   "source": [
    "## I. 文本分类的两类模型：Generative和Discriminative\n",
    "- **文本分类问题：** input X是sentence，label y是该sentence的类型标签。求$\\hat{y}=\\underset{y}{argmax}P(y|X)$\n",
    "- **关键：** 找到$P(y|X)$的分布形态\n",
    "- **方法：**\n",
    "  - 概率方法：生成模型和判别模型（本节主要关注这两种方法的差异）\n",
    "  - 非概率方法：SVM，Perceptron，NN不用softmax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1565dcaf",
   "metadata": {},
   "source": [
    "### I.1 Discriminative model和Generative model\n",
    "#### I.1.1 Discriminative model\n",
    "1. 模型训练时：直接对$P(y|X)$的参数建模，用MLE或者CE做目标函数，求解参数θ:\n",
    "$$\\begin{align}\n",
    "&\\hat{θ}=\\underset{θ}{argmax}\\ L(θ) = \\underset{θ}{argmax}\\underset{i}{Σ}logP(y_{i}|X_{i};θ)\\end{align}$$\n",
    "2. 模型推理时：直接用估计的条件概率分布求概率最大的类型:\n",
    "$$\\hat{y}=\\underset{y}{argmax}P(y|X;\\hat{θ})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "382f0cf6",
   "metadata": {},
   "source": [
    "#### I.1.2 Generative model\n",
    "1. 模型训练时：用贝叶斯分析方式对$𝑃(𝑦|𝑋)$做分解，转化为对先验分布$P(y_i;φ)$和似然$P(X|y_i;θ)$建模，用MLE或者CE做目标函数，求解参数θ。\\\n",
    "贝叶斯分析：\\\n",
    "$P(y_i|X) = \\frac{P(X|y_i)*P(y_i)}{P(X)} = \\frac{P(X|y_i)*P(y_i)}{Σ_{y_j\\in{Y}} P(X|y_j)*P(y_j)}$ \\\n",
    "求解MLE：\\\n",
    "$\\hat{θ}=\\underset{θ,φ}{argmax}\\ L(θ,φ) = \\underset{θ,φ}{argmax}\\ \\frac{P(X|y_i;θ)*P(y_i;φ)}{Σ_{y_j\\in{Y}} P(X|y_j;θ)*P(y_j;φ)}$\n",
    "2. 模型推理时：同样利用贝叶斯关系对目标函数做分析，求解优化函数。 \\\n",
    "利用贝叶斯分析： \\\n",
    "$\\hat{y}=\\underset{y}{argmax}P(y|X) = \\underset{y}{argmax}\\frac{P(X|y)*P(y)}{P(X)}$ \\\n",
    "<font color=red>由于y的取值与P(X)无关</font>，因此有：\\\n",
    "$\\hat{y}=\\underset{y}{argmax}\\ P(X|y;\\hat{θ})*P(y;\\hat{φ})=\\underset{y}{argmax}\\ P(X,y;\\hat{θ},\\hat{φ})$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5405c0d",
   "metadata": {},
   "source": [
    "3. 生成模型在处理文本分类问题时，通常会使用语言模型\n",
    "   - 生成模型在将后验概率转化为先验似然之后，在分类问题中，一般会直接用训练集统计先验概率$P(y_i)$。然后分别对各个不同分类的样本集单独训练$P(X|y_i)$。从单个分类数据集而言，可以简写为$P(X)$\n",
    "   - 在自然语言处理的语境中，X就是sentence。计算P(X)也就是计算sentence发生的概率。<font color=blue>语言模型就是处理这类问题的模型，模型的目标就assign probabilities to sequences of words.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "437eaace",
   "metadata": {},
   "source": [
    "### I.2 基于生成模型的BOW model：Naive Bayes\n",
    "#### bag of words\n",
    "- 指将文本视为a bag of words，忽略他们的位置关系，只保留words和他们的frequency信息。处理方式可以用下图表示：\n",
    "<img src=\"./pics/BagOfWords.png\" style=\"zoom:100%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f78b93ee",
   "metadata": {},
   "source": [
    "#### Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f78a53a6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-01T16:25:10.129056Z",
     "start_time": "2023-11-01T16:25:10.124749Z"
    }
   },
   "source": [
    "1. 模型结构\n",
    "![BOW_generative_model](./pics/BOW_generative_model.png) \\\n",
    "图中$θ_y$是在trainning set中用unigram语言模型计算的count-based probability。 \\\n",
    "用公式表达为：$P(X,y)=P(y)* {\\textstyle \\prod_{i=1}^{|X|}}P(x_i|y)=\\frac{c(y)}{Σ_{y_j}c(y_j)}  {\\textstyle \\prod_{i=1}^{|X|}}\\frac{c(x_i, y)}{Σ_{x_k}c(x_k, y)}$\n",
    "2. laplace smoothing \\\n",
    "naive bayes可以用laplace smoothing。<font color=red>这里要注意的是，下面公式中的|V|包含trainning set中所有分类类型y中的所有words，而不仅仅是$x_i$所在的类型中的words。</font>\n",
    "$\\hat P(x_i)=\\frac{C_{train}(x_i)+1}{Σ_{x \\in V}(C_{train}(x)+1)} \n",
    "= \\frac{C_{train}(x_i)+1}{Σ_{x \\in V}C_{train}(x)+|V|}$\n",
    "3. 处理\\<UNK>：可以直接忽略这些词\n",
    "4. stop words: 出现频率极高的词，比如：a, the等 \\\n",
    "stop words可以忽略，也就是直接将他们从trainning set和test set中去掉。\\\n",
    "标记stop words的方法是将training set中所有词语按词频排序，将排名前10-100个词作为stop words。或者单独做一个stop words list。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ff244db",
   "metadata": {},
   "source": [
    "### I.3 基于判别模型的BOW model：logistic regression\n",
    "- 判别模型的训练思路：$\\hat{θ}=\\underset{θ}{argmax}\\ L(θ) = \\underset{θ}{argmax}\\  {\\textstyle \\sum_{i=1}^{|X|}}\\ logP(y_{i}|X_{i};θ)\n",
    "$\n",
    "- <font color=blue>generative classifier与discriminate classifier的简单比较:</font>\n",
    "generative models的求解方式很绕，为了求P(y|X)要先求P(X|y),而disciminative model则直接求P(X|y)。但Distriminative model不能使用简单的count-based decomposition。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cdae62d",
   "metadata": {},
   "source": [
    "#### logistic regression\n",
    "1. 二分类问题：先计算score，再用logistic function转化为probability\n",
    "   1. 模型训练阶段：\n",
    "      - 每个word就是1个feature，$ score_{y|X}={\\textstyle \\sum_{k=1}^{|V|}} θ_{y|x_k}*1\\{x_k\\} + θ_y $ \\\n",
    "      - 用MLE求解：$$\\begin{align} \n",
    "\\hat θ& =\\underset{θ}{argmax}\\ L(θ) \\\\\n",
    "& = \\underset{θ}{argmax}\\ {\\textstyle \\sum_{i=1}^{N}}P(X_i|y_i;θ) \\\\\n",
    "& = \\underset{θ}{argmax}\\ {\\textstyle \\sum_{i=1}^{N}}f(X_i|y_i;θ) \\\\\n",
    "& = \\underset{θ}{argmax}\\ {\\textstyle \\sum_{i=1}^{N}}({\\textstyle \\sum_{k=1}^{|V|}}θ_{y_i|x_k}*1\\{x_{i,k}\\}+θ_{y_i} )\\\\\n",
    "\\end{align}$$\n",
    "      - 用Gradient Descent求解\n",
    "   2. 模型推理阶段：\n",
    "      - 先计算score：$score_{y|X}=θ_y+{\\textstyle \\prod_{i=1}^{|X|}}θ_{y|x_i} \n",
    "$\n",
    "      - 再转化为probability：$P(y|X;θ)=sigmoid(score_{y|X})=\\frac{1}{1+e^{-score_{y|X}}}$\n",
    "\n",
    "2. 多分类问题：先计算score，再用softmax function转化为probability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01fe5603",
   "metadata": {},
   "source": [
    "## II. 评估分类模型\n",
    "### II.1 metrics\n",
    "<img src=\"./pics/ConfusionMatrix.png\" style=\"zoom:100%\">\n",
    "\n",
    "1. Accuracy：$acc(y,\\hat y)=\\frac{1}{|y|}\\sum_{i=1}^{|y|} Count(y_i=\\hat{y}_i)$ \\\n",
    "<font color=red>问题：如果有出现概率非常小的类型，比如P(y=0)=1%，那么分类器只要全判y=1就有acc=99% </font>\n",
    "2. precision（<font color=orange>**识别出来的目标的正确率**</font>）：估$\\hat{y}=1$的样本中，确实是y=1的比例 \\\n",
    "$prec(y, \\hat{y}) = \\frac{c(y=1, \\hat{y}=1)}{c(\\hat{y}=1)} $\n",
    "3. recall（<font color=orange>**有多少比例的目标被识别**</font>）：所有y=1的样本中，被估为$\\hat{y}=1$的比例\\\n",
    "$rec(y, \\hat{y}) = \\frac{c(y=1, \\hat{y}=1)}{c(y=1)} $\n",
    "4. F-measure(F1 score)：$\\frac{1*prec*rec}{prec+rec}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd2d2976",
   "metadata": {},
   "source": [
    "多分类问题的metrics： \\\n",
    "<img src=\"./pics/ConfusionMatrix3class.png\" style=\"zoom:100%\"> \\\n",
    "把图中3个类型用一个指标表达的话，有两种方式：\n",
    "1. macroaveraging：取各个类型的均值\n",
    "2. microaveraging：把表合并成一个对错表，用合并后的表计算\n",
    "\n",
    "<img src=\"./pics/ConfusionMatrix3classin1.png\" style=\"zoom:100%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b7f51c0",
   "metadata": {},
   "source": [
    "### II.2 比较两个模型：statistic test(significant testing)\n",
    "**背景：**\n",
    "1. 有两个模型A和B，在test set x上，A,B的score分别表示为S(A,x)和S(B,x)。这里S可能是prec，rec，F1或者BLEU。\n",
    "2. $δ(x) = S(A,x)-S(B,x)$,如果δ(x)=0.05>0,并不能得出结论model A更好。因为这个0.05的差异可能是test set的随机性造成的。换一组test set得到的结论可能不同。\n",
    "3. 需要有方法能得出model比较的结论到底是否可靠。方法是用statistic test。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5811ac5d",
   "metadata": {},
   "source": [
    "#### 2.2.1 statistical hypothesis testing\n",
    "1. 目标：当$δ(x) = S(A,x)-S(B,x)>0$时，判断δ(x)>0是否真的成立。\n",
    "2. 假设：\n",
    "$$\\begin{align} \n",
    "  H_0 & :δ(x)≤0 \\ (null\\ hypothesis, want\\ to\\ confidently\\ rule\\ out\\ it)\\\\\n",
    "H_1 & :δ(x)＞0\n",
    "\\end{align}$$\n",
    "<font color=red>注：null hypothesis要与目标相反，这样p值小于p-value才能推翻H_0</font>\n",
    "3. testing过程：\\\n",
    "(1) 创建一个以test set为取值范围的随机变量X，也即X的取值是从test set中做抽样而来。取$δ(X) = S(A,X)-S(B,X)$ \\\n",
    "(2) 计算：假如$H_0$是正确的，那么$δ(X)$取到原observed$δ(x)$的值，本例中即$δ(X)=0.05$的概率是多少？也就是:<font color=green>求$P(δ(X)>δ_{observed}|H_0)$ </font>\\\n",
    "(3) 设定一个p-value=0.05或者0.01，如果上一步中的概率小于p-value，那么$H_0$就被推翻。也就是：\\\n",
    "<font color=green>$P(δ(X)>δ(x)|H_0)<p-value$时，$H_1$成立。</font>\n",
    "4. 求$P(δ(X)>δ(x)|H_0)$的方法: \\\n",
    "一般统计学中是根据假设的分布来求解，做参数检验。但是这里没有假设的分布，所以改用非参数检验的方法：bootstrap test。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7665f4cc",
   "metadata": {},
   "source": [
    "#### 2.2.2 unpaired and paired test\n",
    "有paired和unpaired两种test。\n",
    "1. 同一个样本x可以在两个model上得到可比的两个结果时，是paired test。\n",
    "2. 一个model在两个样本上出来的结果做比较，则是unpaired test。 \\\n",
    "这里是第一种情况，所以用paired test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e20694b5",
   "metadata": {},
   "source": [
    "#### 2.2.3 paired bootstrap test\n",
    "1. bootstrap test：重复在一个样本池(称为bootstrap samples)中做放回抽样。\n",
    "2. 该方法假设了当前的抽样样本能够代表真实分布。本质上是用test set，通过重复抽样来构造多个virtual test set"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
